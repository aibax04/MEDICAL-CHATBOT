{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_5ftJtk_RPGwskkYfaFGx21SBduyqwS44EGQ2stdCX3rJRdhB1s32dos2WfAJMH6hRDhq3B\"\n",
    "\n",
    "PINECONE_API_ENV = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GALE\n",
      "The\n",
      "ENCYCLOPEDIA\n",
      "M\n",
      "EDICINE\n",
      "of\n",
      "SECOND EDITION\n",
      "G ALE\n",
      "The\n",
      "ENCYCLOPEDIA\n",
      "M\n",
      "EDICINE\n",
      "of\n",
      "SECOND EDITION\n",
      "V O L U M E\n",
      "1\n",
      "A-B\n",
      "JACQUELINE L. LONGE, EDITOR\n",
      "DEIRDRE S. BLANCHFIELD, ASSOCIATE EDITOR\n",
      "The GALE Since this page cannot legibly accommodate all copyright notices,the\n",
      "acknowledgments constitute an extension of the copyright notice.\n",
      "ENCYCLOPEDIA\n",
      "While every effort has been made to ensure the reliability of the infor-\n",
      "mation presented in this publication,the Gale Group neither guarantees\n",
      "of MEDICINE\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def load_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF using pdfplumber.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Extract text\n",
    "extracted_data = load_pdf(r\"C:\\Users\\mohda\\OneDrive\\Desktop\\MEDICAL-CHATBOT\\data\\Medical_book.pdf\")\n",
    "print(extracted_data[:500])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 5720 text chunks from PDF.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split extracted text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_text(extracted_data)\n",
    "\n",
    "print(f\"Extracted {len(text_chunks)} text chunks from PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embedding Vector: [-0.004146425519138575, 0.05755056068301201, -0.001845396007411182, 0.014783775433897972, -0.04701027646660805, 0.01919114775955677, 0.003776268567889929, -0.07476205378770828, 0.04135068878531456, -0.024365302175283432]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# üîπ Load the Sentence Transformer model for embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# üîπ Convert a sample text into an embedding vector\n",
    "text = \"How does the heart function?\"\n",
    "query_embedding = embedding_model.embed_query(text)\n",
    "\n",
    "print(\"Generated Embedding Vector:\", query_embedding[:10])  # Print first 10 values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to index: medicalchatbot\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# üîπ Step 1: Initialize Pinecone Client\n",
    "pc = Pinecone(api_key=\"pcsk_5ftJtk_RPGwskkYfaFGx21SBduyqwS44EGQ2stdCX3rJRdhB1s32dos2WfAJMH6hRDhq3B\")  # Replace with your API key\n",
    "\n",
    "# üîπ Step 2: Define Index Name and Region\n",
    "index_name = \"medicalchatbot\"\n",
    "region = \"us-east-1\"  # Change this to match your Pinecone region\n",
    "\n",
    "# üîπ Step 3: Check and Connect to Index\n",
    "# if index_name not in pc.list_indexes():\n",
    "#     print(f\"Index '{index_name}' not found. Creating it...\")\n",
    "#     pc.create_index(\n",
    "#         name=index_name,\n",
    "#         dimension=384,  # Ensure this matches your embedding model\n",
    "#         metric=\"cosine\",\n",
    "#         spec={ \"cloud\": \"aws\", \"region\": region}\n",
    "#     )\n",
    "\n",
    "# Connect to the existing index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to index: {index_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted 5896 text chunks from PDF.\n",
      "Connected to index: medicalchatbot\n",
      "Upserted 100 vectors so far.\n",
      "Upserted 200 vectors so far.\n",
      "Upserted 300 vectors so far.\n",
      "Upserted 400 vectors so far.\n",
      "Upserted 500 vectors so far.\n",
      "Upserted 600 vectors so far.\n",
      "Upserted 700 vectors so far.\n",
      "Upserted 800 vectors so far.\n",
      "Upserted 900 vectors so far.\n",
      "Upserted 1000 vectors so far.\n",
      "Upserted 1100 vectors so far.\n",
      "Upserted 1200 vectors so far.\n",
      "Upserted 1300 vectors so far.\n",
      "Upserted 1400 vectors so far.\n",
      "Upserted 1500 vectors so far.\n",
      "Upserted 1600 vectors so far.\n",
      "Upserted 1700 vectors so far.\n",
      "Upserted 1800 vectors so far.\n",
      "Upserted 1900 vectors so far.\n",
      "Upserted 2000 vectors so far.\n",
      "Upserted 2100 vectors so far.\n",
      "Upserted 2200 vectors so far.\n",
      "Upserted 2300 vectors so far.\n",
      "Upserted 2400 vectors so far.\n",
      "Upserted 2500 vectors so far.\n",
      "Upserted 2600 vectors so far.\n",
      "Upserted 2700 vectors so far.\n",
      "Upserted 2800 vectors so far.\n",
      "Upserted 2900 vectors so far.\n",
      "Upserted 3000 vectors so far.\n",
      "Upserted 3100 vectors so far.\n",
      "Upserted 3200 vectors so far.\n",
      "Upserted 3300 vectors so far.\n",
      "Upserted 3400 vectors so far.\n",
      "Upserted 3500 vectors so far.\n",
      "Upserted 3600 vectors so far.\n",
      "Upserted 3700 vectors so far.\n",
      "Upserted 3800 vectors so far.\n",
      "Upserted 3900 vectors so far.\n",
      "Upserted 4000 vectors so far.\n",
      "Upserted 4100 vectors so far.\n",
      "Upserted 4200 vectors so far.\n",
      "Upserted 4300 vectors so far.\n",
      "Upserted 4400 vectors so far.\n",
      "Upserted 4500 vectors so far.\n",
      "Upserted 4600 vectors so far.\n",
      "Upserted 4700 vectors so far.\n",
      "Upserted 4800 vectors so far.\n",
      "Upserted 4900 vectors so far.\n",
      "Upserted 5000 vectors so far.\n",
      "Upserted 5100 vectors so far.\n",
      "Upserted 5200 vectors so far.\n",
      "Upserted 5300 vectors so far.\n",
      "Upserted 5400 vectors so far.\n",
      "Upserted 5500 vectors so far.\n",
      "Upserted 5600 vectors so far.\n",
      "Upserted 5700 vectors so far.\n",
      "Upserted 5800 vectors so far.\n",
      "Upserted 5896 vectors so far.\n",
      "‚úÖ PDF text chunks successfully converted to vectors and stored in Pinecone!\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF for PDF text extraction\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "\n",
    "# üîπ Step 1: Extract Text from Uploaded PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Path to the uploaded PDF\n",
    "pdf_path = r\"C:\\Users\\mohda\\OneDrive\\Desktop\\MEDICAL-CHATBOT\\data\\Medical_book.pdf\"  # Replace with the actual path\n",
    "\n",
    "# Extract text from PDF\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# üîπ Step 2: Split Extracted Text into Smaller Chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_text(extracted_text)\n",
    "\n",
    "print(f\"‚úÖ Extracted {len(text_chunks)} text chunks from PDF.\")\n",
    "\n",
    "# üîπ Step 3: Initialize Pinecone Client\n",
    "pc = Pinecone(api_key=\"pcsk_5ftJtk_RPGwskkYfaFGx21SBduyqwS44EGQ2stdCX3rJRdhB1s32dos2WfAJMH6hRDhq3B\")  # Replace with your actual API Key\n",
    "\n",
    "# Define Pinecone index details\n",
    "index_name = \"medicalchatbot\"\n",
    "expected_dim = 384  # Ensure embeddings match this dimension\n",
    "\n",
    "\n",
    "\n",
    "# Connect to the existing index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to index: {index_name}\")\n",
    "\n",
    "# üîπ Step 4: Convert Text Chunks into Vector Embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.embed_documents(text_chunks)\n",
    "\n",
    "# üîπ Step 5: Format Data for Pinecone Upsert\n",
    "vectors = [\n",
    "    {\"id\": f\"doc_{i}\", \"values\": embeddings[i], \"metadata\": {\"text\": text_chunks[i]}}\n",
    "    for i in range(len(text_chunks))\n",
    "]\n",
    "\n",
    "# üîπ Step 6: Store Vectors in Pinecone\n",
    "batch_size = 100  # To prevent exceeding Pinecone's request limits\n",
    "for i in range(0, len(vectors), batch_size):\n",
    "    index.upsert(vectors=vectors[i : i + batch_size])\n",
    "    print(f\"Upserted {i + len(vectors[i : i + batch_size])} vectors so far.\")\n",
    "\n",
    "print(\"‚úÖ PDF text chunks successfully converted to vectors and stored in Pinecone!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Pinecone index: medicalchatbot\n",
      "\n",
      "üîç Query Results:\n",
      "üîπ Confidence Score: 0.5543\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.5457\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.5374\n",
      "üìÑ Retrieved Text: heart are attached to the chest and extremities. The infor-\n",
      "mation is displayed on a monitor screen or a paper tape\n",
      "in the form of waves. Reduced blood and oxygen supply\n",
      "to the heart shows as a change in the shape of the waves.\n",
      "‚Ä¢ Noninvasive vascular tests. These involve measuring\n",
      "blood pressure in various parts of the body and compar-\n",
      "ing the results from each location. When there is a\n",
      "KEY TERMS\n",
      "Arterial fibrillation‚ÄîAn arrhythmia; chaotic quiv-\n",
      "ering of the arteries.\n",
      "\n",
      "üîπ Confidence Score: 0.4930\n",
      "üìÑ Retrieved Text: make the heart beat properly can be implanted under the\n",
      "skin during a simple operation. Leads from the pacemak-\n",
      "er are anchored to the right side of the heart. Pacemakers\n",
      "are used to correct bradycardia and are sometimes used\n",
      "after surgical or catheter ablation.\n",
      "Automatic implantable defibrillators correct life-\n",
      "threatening ventricular arrhythmias by recognizing them\n",
      "and then restoring a normal heart rhythm by pacing the\n",
      "heart or giving it an electric shock. They are implanted\n",
      "\n",
      "üîπ Confidence Score: 0.4906\n",
      "üìÑ Retrieved Text: Left ventricle‚ÄîOne of the lower chambers of the\n",
      "heart, which pumps blood to the aorta.\n",
      "Murmur‚ÄîAn abnormal heart sound that can\n",
      "reflect a valve dysfunction.\n",
      "Rheumatic fever‚ÄîA bacterial infection that often\n",
      "causes heart inflammation.\n",
      "Pulmonary valve‚ÄîThe valve located between the\n",
      "pulmonary artery and the right ventricle, which\n",
      "brings blood to the lungs.\n",
      "ease is curable. Patients suffering mild stenosis can usu-\n",
      "ally lead a normal life; a minority of the patients progress\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# üîπ Initialize Pinecone Client\n",
    "pc = Pinecone(api_key=\"pcsk_5ftJtk_RPGwskkYfaFGx21SBduyqwS44EGQ2stdCX3rJRdhB1s32dos2WfAJMH6hRDhq3B\")  # Replace with your API Key\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# üîπ Step 2: Define Index Name\n",
    "index_name = \"medicalchatbot\"\n",
    "\n",
    "# üîπ Step 3: Get the Host of the Index\n",
    "index_info = pc.describe_index(index_name)\n",
    "host_url = \"https://medicalchatbot-kvk4kva.svc.aped-4627-b74a.pinecone.io\"  # Extract host URL\n",
    "\n",
    "# üîπ Step 4: Connect to Pinecone Index with Host\n",
    "index = pc.Index(index_name, host=host_url)\n",
    "\n",
    "print(f\"‚úÖ Connected to Pinecone index: {index_name}\")\n",
    "\n",
    "index_name = \"medicalchatbot\"\n",
    "\n",
    "\n",
    "# üîπ Initialize Embedding Model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# üîπ Connect to Existing Pinecone Index\n",
    "\n",
    "# üîπ Define Query\n",
    "query = \"what are headaches?\"\n",
    "\n",
    "\n",
    "\n",
    "query_result = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=5,  # More results\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Query Results:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    score = match[\"score\"]\n",
    "    text = match[\"metadata\"].get(\"text\", \"‚ö† No matching text found\")\n",
    "    print(f\"üîπ Confidence Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Retrieved Text: {text}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 11096},\n",
      "                'medical_book_text': {'vector_count': 2}},\n",
      " 'total_vector_count': 11098}\n"
     ]
    }
   ],
   "source": [
    "# Describe your Pinecone index\n",
    "index_stats = index.describe_index_stats()\n",
    "print(\"Index Stats:\", index_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Stored Data in Pinecone:\n",
      "üìÑ Text: No text found\n",
      "üìÑ Text: nonprescription (over-the-counter) drugs without first\n",
      "checking with a physician.\n",
      "Because the atypical antipsychotics may cause low-\n",
      "ering of blood pressure, care should be used when these\n",
      "drugs are taken at the same time as other drugs which\n",
      "lower blood pressure.\n",
      "Quetiapine has many interactions. Doses should be\n",
      "carefully adjusted when quetiapine is used with keto-\n",
      "conazole, itraconazole, fluconazole, erythromycin, car-\n",
      "bamazepine, barbiturates, rifampin or glucocorticoids\n",
      "üìÑ Text: Publishers, May 1996.\n",
      "PERIODICALS\n",
      "McDougle, C. J. ‚ÄúA double-blind, placebo-controlled study of\n",
      "risperidone addition in serotonin reuptake inhibitor-refrac-\n",
      "tory obsessive-compulsive disorder.‚Äù Archives of General\n",
      "Psychiatry (August 2000): 794.\n",
      "Samuel David Uretsky, PharmD\n",
      "Antiretroviral drugs\n",
      "Definition\n",
      "Antiretroviral drugs inhibit the reproduction of\n",
      "retroviruses‚Äîviruses composed of RNA rather than\n",
      "DNA. The best known of this group is HIV, human\n",
      "üìÑ Text: DNA copy. The nucleoside reverse transcriptase\n",
      "inhibitors are incorporated into the DNA strand. This is a\n",
      "faulty DNA molecule which is incapable of reproducing.\n",
      "The non-nucleoside reverse transcriptase in-\n",
      "hibitors (NNRTIs), such as delavirdine (Rescriptor),\n",
      "loviride, and nevirapine (Viramune) act by binding\n",
      "directly to the reverse transcriptase molecule, inhibiting\n",
      "its activity.\n",
      "Protease inhibitors, such as indinavir (Crixivan),\n",
      "nelfinavir (Viracept), ritonavir (Norvir), and saquinavir\n",
      "üìÑ Text: Pregnancy\n",
      "The atypical antipsychotics have not been proved\n",
      "safe in pregnancy. They should be used only when\n",
      "clearly needed and when potential benefits outweigh\n",
      "potential hazards to the fetus. These drugs have not been\n",
      "reported in human milk.\n",
      "Side effects\n",
      "Although the atypical antipsychotics are less likely to\n",
      "cause involuntary movements than the older antipsychotic\n",
      "drugs, they still have a large number of adverse effects.\n",
      "The following list is not complete. Review each drug indi-\n"
     ]
    }
   ],
   "source": [
    "query_result = index.query(\n",
    "    vector=[0] * 384,  # Dummy query vector\n",
    "    top_k=5,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "# Print stored text chunks\n",
    "print(\"\\nüîç Stored Data in Pinecone:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    print(f\"üìÑ Text: {match['metadata'].get('text', 'No text found')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load the same embedding model used for storage\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert query into vector\n",
    "query_text = \"What are allergies?\"\n",
    "query_embedding = embedding_model.embed_query(query_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query Results:\n",
      "üîπ Confidence Score: 0.7797\n",
      "üìÑ Retrieved Text: GALE ENCYCLOPEDIA OF MEDICINE 2\n",
      "118\n",
      "Allergies\n",
      "\n",
      "üîπ Confidence Score: 0.7743\n",
      "üìÑ Retrieved Text: GALE ENCYCLOPEDIA OF MEDICINE 2\n",
      "121\n",
      "Allergies\n",
      "\n",
      "üîπ Confidence Score: 0.7132\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.7030\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.6950\n",
      "üìÑ Retrieved Text: ders Co., 1993.\n",
      "Lawlor, G. J. Jr., T. J. Fischer, and D. C. Adelman. Manual of\n",
      "Allergy and Immunology. Boston: Little, Brown and Co.,\n",
      "1995.\n",
      "Novick, N. L. You Can Do Something About Your Allergies.\n",
      "New York: Macmillan, 1994.\n",
      "Weil, A. Natural Health, Natural Medicine: A Comprehensive\n",
      "Manual for Wellness and Self-Care. New York: Houghton\n",
      "Mifflin, 1995.\n",
      "Richard Robinson\n",
      "Allergies\n",
      "Definition\n",
      "Allergies are abnormal reactions of the immune sys-\n",
      "tem that occur in response to otherwise harmless sub-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_result = index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Query Results:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    score = match[\"score\"]\n",
    "    text = match[\"metadata\"].get(\"text\", \"‚ö† No matching text found\")\n",
    "    print(f\"üîπ Confidence Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Retrieved Text: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"What are heart attacks?\"\n",
    "query_embedding = embedding_model.embed_query(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query Results:\n",
      "üîπ Confidence Score: 0.6189\n",
      "üìÑ Retrieved Text: some patients after a heart attack. Heart attacks dam-\n",
      "age and weaken the heart muscle, and the damage con-\n",
      "tinues even after a person recovers from the attack. This\n",
      "medicine helps slow down further damage to the heart.\n",
      "ACE inhibitors also may be used to treat congestive\n",
      "heart failure.\n",
      "Description\n",
      "ACE inhibitors are available only with a physician‚Äôs\n",
      "prescription and come in tablet, capsule, and injectable\n",
      "forms. Some commonly used ACE inhibitors are\n",
      "\n",
      "üîπ Confidence Score: 0.6042\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.5980\n",
      "üìÑ Retrieved Text: infarction (heart attack). It also may be done on some-\n",
      "one with heart disease, such as cardiomyopathy or\n",
      "rheumatic fever.\n",
      "Although the presence of antimyocardial antibodies\n",
      "does not diagnose heart damage or disease, there is a\n",
      "connection between the presence of these antibodies and\n",
      "damage to the heart. The amount of damage, however,\n",
      "cannot be predicted by the amount of antibodies.\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2\n",
      "291\n",
      "Antimyocardial antibody test\n",
      "\n",
      "üîπ Confidence Score: 0.5947\n",
      "üìÑ Retrieved Text: Myocardial infarction‚ÄîCommonly known as a\n",
      "heart attack. Sudden death of part of the heart\n",
      "muscle, characterized, in most cases, by severe,\n",
      "unremitting chest pain.\n",
      "traceptives, and opiates, among others. The patient may\n",
      "also need to cut back on strenuous activities temporarily,\n",
      "because exercise can also elevate AST for a day or two.\n",
      "Risks\n",
      "Risks for this test are minimal, but may include\n",
      "slight bleeding from the blood-drawing site, fainting or\n",
      "feeling lightheaded after venipuncture, or hematoma\n",
      "\n",
      "üîπ Confidence Score: 0.5928\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_result = index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Query Results:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    score = match[\"score\"]\n",
    "    text = match[\"metadata\"].get(\"text\", \"‚ö† No matching text found\")\n",
    "    print(f\"üîπ Confidence Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Retrieved Text: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
