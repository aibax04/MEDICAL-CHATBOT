{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_5ftJtk_RPGwskkYfaFGx21SBduyqwS44EGQ2stdCX3rJRdhB1s32dos2WfAJMH6hRDhq3B\"\n",
    "\n",
    "PINECONE_API_ENV = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GALE\n",
      "The\n",
      "ENCYCLOPEDIA\n",
      "M\n",
      "EDICINE\n",
      "of\n",
      "SECOND EDITION\n",
      "G ALE\n",
      "The\n",
      "ENCYCLOPEDIA\n",
      "M\n",
      "EDICINE\n",
      "of\n",
      "SECOND EDITION\n",
      "V O L U M E\n",
      "1\n",
      "A-B\n",
      "JACQUELINE L. LONGE, EDITOR\n",
      "DEIRDRE S. BLANCHFIELD, ASSOCIATE EDITOR\n",
      "The GALE Since this page cannot legibly accommodate all copyright notices,the\n",
      "acknowledgments constitute an extension of the copyright notice.\n",
      "ENCYCLOPEDIA\n",
      "While every effort has been made to ensure the reliability of the infor-\n",
      "mation presented in this publication,the Gale Group neither guarantees\n",
      "of MEDICINE\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def load_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF using pdfplumber.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Extract text\n",
    "extracted_data = load_pdf(r\"C:\\Users\\mohda\\OneDrive\\Desktop\\MEDICAL-CHATBOT\\data\\Medical_book.pdf\")\n",
    "print(extracted_data[:500])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 5720 text chunks from PDF.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split extracted text into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_text(extracted_data)\n",
    "\n",
    "print(f\"Extracted {len(text_chunks)} text chunks from PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Embedding Vector: [-0.004146425519138575, 0.05755056068301201, -0.001845396007411182, 0.014783775433897972, -0.04701027646660805, 0.01919114775955677, 0.003776268567889929, -0.07476205378770828, 0.04135068878531456, -0.024365302175283432]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# üîπ Load the Sentence Transformer model for embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# üîπ Convert a sample text into an embedding vector\n",
    "text = \"How does the heart function?\"\n",
    "query_embedding = embedding_model.embed_query(text)\n",
    "\n",
    "print(\"Generated Embedding Vector:\", query_embedding[:10])  # Print first 10 values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = download_hugging_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to index: medicalchatbot\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# üîπ Step 1: Initialize Pinecone Client\n",
    "pc = Pinecone(api_key=\"pcsk_5ftJtk_RPGwskkYfaFGx21SBduyqwS44EGQ2stdCX3rJRdhB1s32dos2WfAJMH6hRDhq3B\")  # Replace with your API key\n",
    "\n",
    "# üîπ Step 2: Define Index Name and Region\n",
    "index_name = \"medicalchatbot\"\n",
    "region = \"us-east-1\"  # Change this to match your Pinecone region\n",
    "\n",
    "\n",
    "# Connect to the existing index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to index: {index_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extracted 5896 text chunks from PDF.\n",
      "Connected to index: medicalchatbot\n",
      "Upserted 100 vectors so far.\n",
      "Upserted 200 vectors so far.\n",
      "Upserted 300 vectors so far.\n",
      "Upserted 400 vectors so far.\n",
      "Upserted 500 vectors so far.\n",
      "Upserted 600 vectors so far.\n",
      "Upserted 700 vectors so far.\n",
      "Upserted 800 vectors so far.\n",
      "Upserted 900 vectors so far.\n",
      "Upserted 1000 vectors so far.\n",
      "Upserted 1100 vectors so far.\n",
      "Upserted 1200 vectors so far.\n",
      "Upserted 1300 vectors so far.\n",
      "Upserted 1400 vectors so far.\n",
      "Upserted 1500 vectors so far.\n",
      "Upserted 1600 vectors so far.\n",
      "Upserted 1700 vectors so far.\n",
      "Upserted 1800 vectors so far.\n",
      "Upserted 1900 vectors so far.\n",
      "Upserted 2000 vectors so far.\n",
      "Upserted 2100 vectors so far.\n",
      "Upserted 2200 vectors so far.\n",
      "Upserted 2300 vectors so far.\n",
      "Upserted 2400 vectors so far.\n",
      "Upserted 2500 vectors so far.\n",
      "Upserted 2600 vectors so far.\n",
      "Upserted 2700 vectors so far.\n",
      "Upserted 2800 vectors so far.\n",
      "Upserted 2900 vectors so far.\n",
      "Upserted 3000 vectors so far.\n",
      "Upserted 3100 vectors so far.\n",
      "Upserted 3200 vectors so far.\n",
      "Upserted 3300 vectors so far.\n",
      "Upserted 3400 vectors so far.\n",
      "Upserted 3500 vectors so far.\n",
      "Upserted 3600 vectors so far.\n",
      "Upserted 3700 vectors so far.\n",
      "Upserted 3800 vectors so far.\n",
      "Upserted 3900 vectors so far.\n",
      "Upserted 4000 vectors so far.\n",
      "Upserted 4100 vectors so far.\n",
      "Upserted 4200 vectors so far.\n",
      "Upserted 4300 vectors so far.\n",
      "Upserted 4400 vectors so far.\n",
      "Upserted 4500 vectors so far.\n",
      "Upserted 4600 vectors so far.\n",
      "Upserted 4700 vectors so far.\n",
      "Upserted 4800 vectors so far.\n",
      "Upserted 4900 vectors so far.\n",
      "Upserted 5000 vectors so far.\n",
      "Upserted 5100 vectors so far.\n",
      "Upserted 5200 vectors so far.\n",
      "Upserted 5300 vectors so far.\n",
      "Upserted 5400 vectors so far.\n",
      "Upserted 5500 vectors so far.\n",
      "Upserted 5600 vectors so far.\n",
      "Upserted 5700 vectors so far.\n",
      "Upserted 5800 vectors so far.\n",
      "Upserted 5896 vectors so far.\n",
      "‚úÖ PDF text chunks successfully converted to vectors and stored in Pinecone!\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF for PDF text extraction\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "\n",
    "# üîπ Step 1: Extract Text from Uploaded PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Path to the uploaded PDF\n",
    "pdf_path = r\"C:\\Users\\mohda\\OneDrive\\Desktop\\MEDICAL-CHATBOT\\data\\Medical_book.pdf\"  # Replace with the actual path\n",
    "\n",
    "# Extract text from PDF\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# üîπ Step 2: Split Extracted Text into Smaller Chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_text(extracted_text)\n",
    "\n",
    "print(f\"‚úÖ Extracted {len(text_chunks)} text chunks from PDF.\")\n",
    "\n",
    "# üîπ Step 3: Initialize Pinecone Client\n",
    "pc = Pinecone(api_key=\"pcsk_5ftJtk_RPGwskkYfaFGx21SBduyqwS44EGQ2stdCX3rJRdhB1s32dos2WfAJMH6hRDhq3B\")  # Replace with your actual API Key\n",
    "\n",
    "# Define Pinecone index details\n",
    "index_name = \"medicalchatbot\"\n",
    "expected_dim = 384  # Ensure embeddings match this dimension\n",
    "\n",
    "\n",
    "\n",
    "# Connect to the existing index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to index: {index_name}\")\n",
    "\n",
    "# üîπ Step 4: Convert Text Chunks into Vector Embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.embed_documents(text_chunks)\n",
    "\n",
    "# üîπ Step 5: Format Data for Pinecone Upsert\n",
    "vectors = [\n",
    "    {\"id\": f\"doc_{i}\", \"values\": embeddings[i], \"metadata\": {\"text\": text_chunks[i]}}\n",
    "    for i in range(len(text_chunks))\n",
    "]\n",
    "\n",
    "# üîπ Step 6: Store Vectors in Pinecone\n",
    "batch_size = 100  # To prevent exceeding Pinecone's request limits\n",
    "for i in range(0, len(vectors), batch_size):\n",
    "    index.upsert(vectors=vectors[i : i + batch_size])\n",
    "    print(f\"Upserted {i + len(vectors[i : i + batch_size])} vectors so far.\")\n",
    "\n",
    "print(\"‚úÖ PDF text chunks successfully converted to vectors and stored in Pinecone!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Pinecone index: medicalchatbot\n",
      "\n",
      "üîç Query Results:\n",
      "üîπ Confidence Score: 0.7456\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.7347\n",
      "üìÑ Retrieved Text: face. A sample of the patient‚Äôs blood serum is\n",
      "added, and excess proteins are removed. A second\n",
      "antibody coupled to an enzyme is added, followed\n",
      "by a chemical that will cause a color reaction that\n",
      "can be measured by a special instrument.\n",
      "Human immunodeficiency virus (HIV)‚ÄîA transmis-\n",
      "sible retrovirus that causes AIDS in humans. Two\n",
      "forms of HIV are now recognized: HIV-1, which caus-\n",
      "es most cases of AIDS in Europe, North and South\n",
      "America, and most parts of Africa; and HIV-2, which\n",
      "\n",
      "üîπ Confidence Score: 0.6977\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.6941\n",
      "üìÑ Retrieved Text: Acquired immune deficiency syndrome (AIDS) is an\n",
      "infectious disease caused by the human immunodeficien-\n",
      "cy virus (HIV). It was first recognized in the United States\n",
      "in 1981. AIDS is the advanced form of infection with the\n",
      "HIV virus, which may not cause recognizable disease for a\n",
      "long period after the initial exposure (latency). No vaccine\n",
      "is currently available to prevent HIV infection. At present,\n",
      "all forms of AIDS therapy are focused on improving the\n",
      "\n",
      "üîπ Confidence Score: 0.6851\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone as PineconeVectorStore\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# üîπ Initialize Pinecone Client\n",
    "pc = Pinecone(api_key=\"pcsk_5ftJtk_RPGwskkYfaFGx21SBduyqwS44EGQ2stdCX3rJRdhB1s32dos2WfAJMH6hRDhq3B\")  # Replace with your API Key\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# üîπ Step 2: Define Index Name\n",
    "index_name = \"medicalchatbot\"\n",
    "\n",
    "# üîπ Step 3: Get the Host of the Index\n",
    "index_info = pc.describe_index(index_name)\n",
    "host_url = \"https://medicalchatbot-kvk4kva.svc.aped-4627-b74a.pinecone.io\"  # Extract host URL\n",
    "\n",
    "# üîπ Step 4: Connect to Pinecone Index with Host\n",
    "index = pc.Index(index_name, host=host_url)\n",
    "\n",
    "print(f\"‚úÖ Connected to Pinecone index: {index_name}\")\n",
    "\n",
    "index_name = \"medicalchatbot\"\n",
    "\n",
    "\n",
    "# üîπ Initialize Embedding Model\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# üîπ Connect to Existing Pinecone Index\n",
    "\n",
    "# üîπ Define Query\n",
    "query = \"what are headaches?\"\n",
    "\n",
    "\n",
    "\n",
    "query_result = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=5,  # More results\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Query Results:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    score = match[\"score\"]\n",
    "    text = match[\"metadata\"].get(\"text\", \"‚ö† No matching text found\")\n",
    "    print(f\"üîπ Confidence Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Retrieved Text: {text}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index Stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 11096},\n",
      "                'medical_book_text': {'vector_count': 2}},\n",
      " 'total_vector_count': 11098}\n"
     ]
    }
   ],
   "source": [
    "# Describe your Pinecone index\n",
    "index_stats = index.describe_index_stats()\n",
    "print(\"Index Stats:\", index_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Stored Data in Pinecone:\n",
      "üìÑ Text: No text found\n",
      "üìÑ Text: nonprescription (over-the-counter) drugs without first\n",
      "checking with a physician.\n",
      "Because the atypical antipsychotics may cause low-\n",
      "ering of blood pressure, care should be used when these\n",
      "drugs are taken at the same time as other drugs which\n",
      "lower blood pressure.\n",
      "Quetiapine has many interactions. Doses should be\n",
      "carefully adjusted when quetiapine is used with keto-\n",
      "conazole, itraconazole, fluconazole, erythromycin, car-\n",
      "bamazepine, barbiturates, rifampin or glucocorticoids\n",
      "üìÑ Text: Publishers, May 1996.\n",
      "PERIODICALS\n",
      "McDougle, C. J. ‚ÄúA double-blind, placebo-controlled study of\n",
      "risperidone addition in serotonin reuptake inhibitor-refrac-\n",
      "tory obsessive-compulsive disorder.‚Äù Archives of General\n",
      "Psychiatry (August 2000): 794.\n",
      "Samuel David Uretsky, PharmD\n",
      "Antiretroviral drugs\n",
      "Definition\n",
      "Antiretroviral drugs inhibit the reproduction of\n",
      "retroviruses‚Äîviruses composed of RNA rather than\n",
      "DNA. The best known of this group is HIV, human\n",
      "üìÑ Text: DNA copy. The nucleoside reverse transcriptase\n",
      "inhibitors are incorporated into the DNA strand. This is a\n",
      "faulty DNA molecule which is incapable of reproducing.\n",
      "The non-nucleoside reverse transcriptase in-\n",
      "hibitors (NNRTIs), such as delavirdine (Rescriptor),\n",
      "loviride, and nevirapine (Viramune) act by binding\n",
      "directly to the reverse transcriptase molecule, inhibiting\n",
      "its activity.\n",
      "Protease inhibitors, such as indinavir (Crixivan),\n",
      "nelfinavir (Viracept), ritonavir (Norvir), and saquinavir\n",
      "üìÑ Text: Pregnancy\n",
      "The atypical antipsychotics have not been proved\n",
      "safe in pregnancy. They should be used only when\n",
      "clearly needed and when potential benefits outweigh\n",
      "potential hazards to the fetus. These drugs have not been\n",
      "reported in human milk.\n",
      "Side effects\n",
      "Although the atypical antipsychotics are less likely to\n",
      "cause involuntary movements than the older antipsychotic\n",
      "drugs, they still have a large number of adverse effects.\n",
      "The following list is not complete. Review each drug indi-\n"
     ]
    }
   ],
   "source": [
    "query_result = index.query(\n",
    "    vector=[0] * 384,  # Dummy query vector\n",
    "    top_k=5,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "# Print stored text chunks\n",
    "print(\"\\nüîç Stored Data in Pinecone:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    print(f\"üìÑ Text: {match['metadata'].get('text', 'No text found')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Load the same embedding model used for storage\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert query into vector\n",
    "query_text = \"What are fractures?\"\n",
    "query_embedding = embedding_model.embed_query(query_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query Results:\n",
      "üîπ Confidence Score: 0.5550\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.5467\n",
      "üìÑ Retrieved Text: is the development of infection at the site of implantation.\n",
      "Normal results\n",
      "Success in healing a fracture nonunion using bone\n",
      "growth stimulation depends on the type, location, and\n",
      "severity of the fracture and the age and general health of\n",
      "the patient.\n",
      "Resources\n",
      "PERIODICALS\n",
      "Mayo Clinic. ‚ÄúFractures - Treatment Methods are Tailored to\n",
      "the Break.‚Äù Mayo Clinic Health Letter 14, no. 4\n",
      "(Apr.1996):1-3.\n",
      "Tish Davidson\n",
      "Bone infection see Osteomyelitis\n",
      "Bone marrow aspiration \n",
      "and biopsy\n",
      "Definition\n",
      "\n",
      "üîπ Confidence Score: 0.5281\n",
      "üìÑ Retrieved Text: wear and tear, age and less often from inflammation.\n",
      "Osteogenesis imperfecta‚ÄîAlso called brittle bones,\n",
      "this is a condition present at birth in which bones\n",
      "are abnormally fragile, brittle and break easily.\n",
      "Osteomalacia‚ÄîA disease in which bones gradual-\n",
      "ly soften and bend.\n",
      "Osteomyelitis‚ÄîAn infection of the bone marrow\n",
      "and the bone.\n",
      "Osteoporosis‚ÄîA disease which occurs primarily\n",
      "in post-menopausal women in which the amount\n",
      "of bone is reduced or skeletal tissue wastes away.\n",
      "\n",
      "üîπ Confidence Score: 0.5212\n",
      "üìÑ Retrieved Text: healing is too slow. This condition is called fracture\n",
      "nonunion, and it occurs more frequently among adults\n",
      "than children, in people with severe or complex fractures,\n",
      "and in people who smoke.\n",
      "The theory behind applying an electric current to\n",
      "fractures to stimulate healing is based on the fact that\n",
      "the concave side of the bone becomes negatively\n",
      "charged and the convex side is positively charged. It is\n",
      "believed that artificially encouraging this charging with\n",
      "\n",
      "üîπ Confidence Score: 0.5182\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_result = index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Query Results:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    score = match[\"score\"]\n",
    "    text = match[\"metadata\"].get(\"text\", \"‚ö† No matching text found\")\n",
    "    print(f\"üîπ Confidence Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Retrieved Text: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"What is the cure for blisters?\"\n",
    "query_embedding = embedding_model.embed_query(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query Results:\n",
      "üîπ Confidence Score: 0.6274\n",
      "üìÑ Retrieved Text: quickly blisters and deteriorates into open sores that can\n",
      "harbor life-threatening infection.\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2\n",
      "456\n",
      "Bedsores\n",
      "\n",
      "üîπ Confidence Score: 0.5719\n",
      "üìÑ Retrieved Text: called, is the mildest form of the disease. At first, the\n",
      "bacteria cause an itchy, raised area like an insect bite.\n",
      "Within one to two days, inflammation occurs around the\n",
      "raised area, and a blister forms around an area of dying\n",
      "tissue that becomes black in the center. Other symptoms\n",
      "may include shivering and chills. In most cases the bacte-\n",
      "ria remain within the sore. If, however, they spread to the\n",
      "nearest lymph node (or, in rare cases, escape into the\n",
      "\n",
      "üîπ Confidence Score: 0.5638\n",
      "üìÑ Retrieved Text: blister may have to be drained, and a heating pad may\n",
      "help swollen, tender lymph glands. Acetaminophen\n",
      "(Tylenol) may relieve pain, aches, and fever over 101¬∞F\n",
      "(38.3¬∞C).\n",
      "Prognosis\n",
      "In most cases, prompt antibiotic treatment in\n",
      "patients with AIDS cured the infection caused by either\n",
      "variety of the bacteria, and patients may resume normal\n",
      "life. Early diagnosis is crucial to a cure.\n",
      "Prevention\n",
      "Studies suggest that antibiotics may prevent the dis-\n",
      "\n",
      "üîπ Confidence Score: 0.5443\n",
      "üìÑ Retrieved Text: applied to the burn since it prevents heat from escaping\n",
      "and drives the burning process deeper into the skin.\n",
      "If the burn is minor, it may be cleaned gently with\n",
      "soap and water. Blisters should not be broken. If the skin\n",
      "of the burned area is unbroken and it is not likely to be\n",
      "further irritated by pressure or friction, the burn should\n",
      "be left exposed to the air to promote healing. If the skin\n",
      "is broken or apt to be disturbed, the burned area should\n",
      "\n",
      "üîπ Confidence Score: 0.5250\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_result = index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Query Results:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    score = match[\"score\"]\n",
    "    text = match[\"metadata\"].get(\"text\", \"‚ö† No matching text found\")\n",
    "    print(f\"üîπ Confidence Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Retrieved Text: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"what is HIV?\"\n",
    "query_embedding = embedding_model.embed_query(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query Results:\n",
      "üîπ Confidence Score: 0.7456\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.7347\n",
      "üìÑ Retrieved Text: face. A sample of the patient‚Äôs blood serum is\n",
      "added, and excess proteins are removed. A second\n",
      "antibody coupled to an enzyme is added, followed\n",
      "by a chemical that will cause a color reaction that\n",
      "can be measured by a special instrument.\n",
      "Human immunodeficiency virus (HIV)‚ÄîA transmis-\n",
      "sible retrovirus that causes AIDS in humans. Two\n",
      "forms of HIV are now recognized: HIV-1, which caus-\n",
      "es most cases of AIDS in Europe, North and South\n",
      "America, and most parts of Africa; and HIV-2, which\n",
      "\n",
      "üîπ Confidence Score: 0.6977\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.6941\n",
      "üìÑ Retrieved Text: Acquired immune deficiency syndrome (AIDS) is an\n",
      "infectious disease caused by the human immunodeficien-\n",
      "cy virus (HIV). It was first recognized in the United States\n",
      "in 1981. AIDS is the advanced form of infection with the\n",
      "HIV virus, which may not cause recognizable disease for a\n",
      "long period after the initial exposure (latency). No vaccine\n",
      "is currently available to prevent HIV infection. At present,\n",
      "all forms of AIDS therapy are focused on improving the\n",
      "\n",
      "üîπ Confidence Score: 0.6851\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_result = index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Query Results:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    score = match[\"score\"]\n",
    "    text = match[\"metadata\"].get(\"text\", \"‚ö† No matching text found\")\n",
    "    print(f\"üîπ Confidence Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Retrieved Text: {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<?, ?it/s]\n",
      "Fetching 1 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import CTransformers\n",
    "\n",
    "llm = CTransformers(model=\"TheBloke/Llama-2-7B-Chat-GGUF\", model_type=\"llama\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"what is adhd\"\n",
    "query_embedding = embedding_model.embed_query(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Query Results:\n",
      "üîπ Confidence Score: 0.8615\n",
      "üìÑ Retrieved Text: disorder (ADHD)\n",
      "Definition\n",
      "Attention-deficit/hyperactivity disorder (ADHD) is\n",
      "a developmental disorder characterized by distractibility,\n",
      "hyperactivity, impulsive behaviors, and the inability to\n",
      "remain focused on tasks or activities.\n",
      "Description\n",
      "ADHD, also known as hyperkinetic disorder (HKD)\n",
      "outside of the United States, is estimated to affect 3-9%\n",
      "of children, and afflicts boys more often than girls.\n",
      "Although difficult to assess in infancy and toddlerhood,\n",
      "\n",
      "üîπ Confidence Score: 0.7425\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.7121\n",
      "üìÑ Retrieved Text: physically clumsy and awkward. Their clumsiness may\n",
      "extend to the social arena, where they are sometimes\n",
      "shunned due to their impulsive and intrusive behavior.\n",
      "Causes and symptoms\n",
      "The causes of ADHD are not known. However, it\n",
      "appears that heredity plays a major role in the develop-\n",
      "ment of ADHD. Children with an ADHD parent or sib-\n",
      "ling are more likely to develop the disorder themselves.\n",
      "Before birth, ADHD children may have been exposed to\n",
      "poor maternal nutrition, viral infections, or maternal\n",
      "\n",
      "üîπ Confidence Score: 0.7057\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n",
      "üîπ Confidence Score: 0.6984\n",
      "üìÑ Retrieved Text: ‚ö† No matching text found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_result = index.query(\n",
    "    vector=query_embedding, \n",
    "    top_k=5, \n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Query Results:\")\n",
    "for match in query_result[\"matches\"]:\n",
    "    score = match[\"score\"]\n",
    "    text = match[\"metadata\"].get(\"text\", \"‚ö† No matching text found\")\n",
    "    print(f\"üîπ Confidence Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Retrieved Text: {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
